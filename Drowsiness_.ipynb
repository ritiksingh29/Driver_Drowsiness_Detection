{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.3.0 (SDL 2.24.2, Python 3.7.0)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout,Conv2D,Flatten,Dense\n",
    "import cv2\n",
    "import pygame\n",
    "from pygame import mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dir, gen=image.ImageDataGenerator(rescale=1./255), shuffle=True,batch_size=1,target_size=(24,24),class_mode='categorical' ):\n",
    "\n",
    "    return gen.flow_from_directory(dir,batch_size=batch_size,shuffle=shuffle,color_mode='grayscale',class_mode=class_mode,target_size=target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2467 images belonging to 4 classes.\n",
      "Found 433 images belonging to 4 classes.\n",
      "77 13\n",
      "(32, 24, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "BS= 32\n",
    "TS=(24,24)\n",
    "train_batch= generator('dataset_new/train',shuffle=True, batch_size=BS,target_size=TS)\n",
    "valid_batch= generator('dataset_new/test',shuffle=True, batch_size=BS,target_size=TS)\n",
    "SPE= len(train_batch.classes)//BS\n",
    "VS = len(valid_batch.classes)//BS\n",
    "print(SPE,VS)\n",
    "\n",
    "img,labels= next(train_batch)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "77/77 [==============================] - 24s 313ms/step - loss: 0.6918 - accuracy: 0.6768 - val_loss: 0.4190 - val_accuracy: 0.7596\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - 25s 328ms/step - loss: 0.4103 - accuracy: 0.8045 - val_loss: 0.4775 - val_accuracy: 0.8055\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - 24s 315ms/step - loss: 0.3499 - accuracy: 0.8283 - val_loss: 0.3636 - val_accuracy: 0.8379\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - 22s 281ms/step - loss: 0.3223 - accuracy: 0.8444 - val_loss: 0.2999 - val_accuracy: 0.8105\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - 20s 262ms/step - loss: 0.2807 - accuracy: 0.8715 - val_loss: 0.2359 - val_accuracy: 0.8454\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - 20s 254ms/step - loss: 0.2479 - accuracy: 0.8871 - val_loss: 0.3262 - val_accuracy: 0.8603\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - 20s 262ms/step - loss: 0.2180 - accuracy: 0.9064 - val_loss: 0.2462 - val_accuracy: 0.8653\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - 19s 252ms/step - loss: 0.1795 - accuracy: 0.9232 - val_loss: 0.4211 - val_accuracy: 0.9027\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - 19s 249ms/step - loss: 0.1409 - accuracy: 0.9396 - val_loss: 0.1903 - val_accuracy: 0.8978\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - 23s 300ms/step - loss: 0.1235 - accuracy: 0.9528 - val_loss: 0.3182 - val_accuracy: 0.9252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f9fec88f208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(24,24,1)),\n",
    "    Conv2D(32,(3,3),activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(train_batch, validation_data=valid_batch,epochs=10,steps_per_epoch=SPE ,validation_steps=VS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <keras.engine.sequential.Sequential object at 0x7fa00894deb8>>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixer.init()\n",
    "sound = mixer.Sound('alarm.wav')\n",
    "face = cv2.CascadeClassifier(\n",
    "    'haar cascade files/haarcascade_frontalface_alt.xml')\n",
    "leye = cv2.CascadeClassifier(\n",
    "    'haar cascade files/haarcascade_lefteye_2splits.xml')\n",
    "reye = cv2.CascadeClassifier(\n",
    "    'haar cascade files/haarcascade_righteye_2splits.xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = ['Close', 'Open']\n",
    "path = os.getcwd()\n",
    "cap = cv2.VideoCapture(0)\n",
    "font = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "count = 0\n",
    "score = 0\n",
    "thicc = 2\n",
    "rpred = [99]\n",
    "lpred = [99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    height, width = frame.shape[:2]\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face.detectMultiScale(gray, minNeighbors=5, scaleFactor=1.1, minSize=(25, 25))\n",
    "    left_eye = leye.detectMultiScale(gray)\n",
    "    right_eye = reye.detectMultiScale(gray)\n",
    "\n",
    "    cv2.rectangle(frame, (0, height-50), (200, height),(0, 0, 0), thickness=cv2.FILLED)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (100, 100, 100), 1)\n",
    "\n",
    "    for (x, y, w, h) in right_eye:\n",
    "        r_eye = frame[y:y+h, x:x+w]\n",
    "        count = count+1\n",
    "        r_eye = cv2.cvtColor(r_eye, cv2.COLOR_BGR2GRAY)\n",
    "        r_eye = cv2.resize(r_eye, (24, 24))\n",
    "        r_eye = r_eye/255\n",
    "        r_eye = r_eye.reshape(24, 24, -1)\n",
    "        r_eye = np.expand_dims(r_eye, axis=0)\n",
    "        rpred = model.predict_classes(r_eye)\n",
    "        if(rpred[0] == 1):\n",
    "            lbl = 'Open'\n",
    "        elif(rpred[0] == 0):\n",
    "            lbl = 'Closed'\n",
    "        break\n",
    "\n",
    "    for (x, y, w, h) in left_eye:\n",
    "        l_eye = frame[y:y+h, x:x+w]\n",
    "        count = count+1\n",
    "        l_eye = cv2.cvtColor(l_eye, cv2.COLOR_BGR2GRAY)\n",
    "        l_eye = cv2.resize(l_eye, (24, 24))\n",
    "        l_eye = l_eye/255\n",
    "        l_eye = l_eye.reshape(24, 24, -1)\n",
    "        l_eye = np.expand_dims(l_eye, axis=0)\n",
    "        lpred = model.predict_classes(l_eye)\n",
    "        if(lpred[0] == 1):\n",
    "            lbl = 'Open'\n",
    "        elif(lpred[0] == 0):\n",
    "            lbl = 'Closed'\n",
    "        break\n",
    "    \n",
    "    if(rpred[0] == 0 and lpred[0] == 0):\n",
    "        score = score+1\n",
    "        cv2.putText(frame, \"Closed\", (10, height-20), font, 1, (255,255,255),1,cv2.LINE_AA)\n",
    "    # if(rpred[0]==1 or lpred[0]==1):\n",
    "    else:\n",
    "        score = score-1\n",
    "        cv2.putText(frame, \"Open\", (10, height-20), font, 1, (255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "    if(score < 0):\n",
    "        score = 0\n",
    "    cv2.putText(frame, 'Score:'+str(score), (100, height-20), font, 1, (255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "    if(score > 15):\n",
    "        # person is feeling sleepy so we beep the alarm\n",
    "        cv2.imwrite(os.path.join(path, 'image.jpg'), frame)\n",
    "\n",
    "        try:\n",
    "            sound.play()\n",
    "        except:  # isplaying = False\n",
    "            pass\n",
    "\n",
    "        if(thicc < 16):\n",
    "            thicc = thicc+2\n",
    "\n",
    "        else:\n",
    "            thicc = thicc-2\n",
    "            if(thicc < 2):\n",
    "                thicc = 2\n",
    "\n",
    "        cv2.rectangle(frame, (0, 0), (width, height),(0,0,255),thicc)\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
